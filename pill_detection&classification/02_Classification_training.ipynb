{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "bFt5WfaAdFbV"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "-V4R-Us3dFbf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import ImageDraw\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.applications import Xception\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 701,
     "status": "ok",
     "timestamp": 1566886813872,
     "user": {
      "displayName": "김정훈",
      "photoUrl": "",
      "userId": "08418669037295379852"
     },
     "user_tz": -540
    },
    "id": "eaFzUQhLdFbm",
    "outputId": "2383b8bc-d7e3-41f9-976f-4a8b0ee79285"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "K.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23655,
     "status": "ok",
     "timestamp": 1566886860178,
     "user": {
      "displayName": "김정훈",
      "photoUrl": "",
      "userId": "08418669037295379852"
     },
     "user_tz": -540
    },
    "id": "ZqfBl2NRdVoZ",
    "outputId": "2810bc94-2cbc-4f3b-da73-c8afe6a7b2e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9kqL4LndsIy"
   },
   "outputs": [],
   "source": [
    "# DATA_PATH = '/gdrive/My Drive/Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o1Ma-sf4dFbs"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 299 #Image_size는 사용하는 pretained 모델 별 추천하는 이미지 사이즈를 주기 위해\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T4vFbkfadFbt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 576,
     "status": "error",
     "timestamp": 1566889486584,
     "user": {
      "displayName": "김정훈",
      "photoUrl": "",
      "userId": "08418669037295379852"
     },
     "user_tz": -540
    },
    "id": "qtj7N-3MdFbz",
    "outputId": "c9d270c9-f924-415c-9545-af9f3bb4b3cc"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ad93bf39faab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# CSV 파일 경로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'df_final_pill_image.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'df_val_final.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'df_class.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/gdrive/My Drive/Colab Notebooks/df_final_pill_image.csv' does not exist: b'/gdrive/My Drive/Colab Notebooks/df_final_pill_image.csv'"
     ]
    }
   ],
   "source": [
    "# 이미지 폴더 경로\n",
    "TRAIN_IMG_PATH = os.path.join(DATA_PATH, 'final_train_pill')\n",
    "VAL_IMG_PATH = os.path.join(DATA_PATH,'img_val_crop')\n",
    "\n",
    "# CSV 파일 경로\n",
    "df_train = pd.read_csv(os.path.join(DATA_PATH, 'df_final_pill_image.csv'))\n",
    "df_val = pd.read_csv(os.path.join(DATA_PATH, 'df_val_final.csv'))\n",
    "df_class = pd.read_csv(os.path.join(DATA_PATH, 'df_class.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMcFFTC_dFb0"
   },
   "outputs": [],
   "source": [
    "def del_index(a):\n",
    "    if '.DS_Store' in a:\n",
    "        del a[a.index('.DS_Store')]\n",
    "        print('.DS_Store 삭제')\n",
    "    if '.ipynb_checkpoints' in a:\n",
    "        del a[a.index('.ipynb_checkpoints')]\n",
    "        print('checkpoints 삭제')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmK4owvodFb2"
   },
   "outputs": [],
   "source": [
    "train_list = os.listdir(TRAIN_IMG_PATH)\n",
    "val_list = os.listdir(VAL_IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V84M1RBOdFb4"
   },
   "outputs": [],
   "source": [
    "del_index(train_list)\n",
    "del_index(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1566888656461,
     "user": {
      "displayName": "김정훈",
      "photoUrl": "",
      "userId": "08418669037295379852"
     },
     "user_tz": -540
    },
    "id": "7yzYg8DhdFb6",
    "outputId": "6bf67779-dc49-4315-dfd4-55fe27dcb6bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file 누락\n",
      "val file 누락 없음!\n"
     ]
    }
   ],
   "source": [
    "# Data 누락 체크\n",
    "if set(list(df_train.img)) == set(train_list) :\n",
    "    print(\"Train file 누락 없음!\")\n",
    "else : \n",
    "    print(\"Train file 누락\")\n",
    "\n",
    "if set(list(df_val.img)) == set(val_list) :\n",
    "    print(\"val file 누락 없음!\")\n",
    "else : \n",
    "    print(\"val file 누락\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1566888682097,
     "user": {
      "displayName": "김정훈",
      "photoUrl": "",
      "userId": "08418669037295379852"
     },
     "user_tz": -540
    },
    "id": "DVr81ah6dFb7",
    "outputId": "2421192b-7898-4926-e338-ca1f827cdb55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data의 타겟 종류 갯수 : 91\n",
      "Class with most count : 655500320\n",
      "Most Count : 22\n",
      "Class with fewest count : 6\n",
      "Mean : 13.934065934065934\n"
     ]
    }
   ],
   "source": [
    "# Data 갯수\n",
    "#print(\"Number of Train Data : {}\".format(df_train.shape[0]))\n",
    "#print(\"Number of Test Data : {}\".format(df_test.shape[0]))\n",
    "#print(\"타겟 클래스 총 갯수 : {}\".format(df_class.shape[0]))\n",
    "print(\"Train Data의 타겟 종류 갯수 : {}\".format(df_train['class'].nunique()))\n",
    "\n",
    "cntEachClass = df_train[\"class\"].value_counts(ascending=False)\n",
    "# Data 정보\n",
    "print(\"Class with most count : {}\".format(cntEachClass.index[0]))\n",
    "print(\"Most Count : {}\".format(cntEachClass.max()))\n",
    "print(\"Class with fewest count : {}\".format(cntEachClass.min()))\n",
    "print(\"Mean : {}\".format(cntEachClass.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1566888690290,
     "user": {
      "displayName": "김정훈",
      "photoUrl": "",
      "userId": "08418669037295379852"
     },
     "user_tz": -540
    },
    "id": "-DXY6UDydFcF",
    "outputId": "100ad82b-ae8c-435c-e1e1-512dd4dc27c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1268, 2)\n",
      "(179, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train[\"class\"] = df_train[\"class\"].astype('str')\n",
    "df_val[\"class\"] = df_val[\"class\"].astype('str')\n",
    "df_train = df_train[['img','class']]\n",
    "df_val = df_val[['img','class']]\n",
    "\n",
    "X_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "X_val = df_val.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "#print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwV_Dh2fdFcG"
   },
   "outputs": [],
   "source": [
    "model_path = './model/'\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-fqSLzDdFcH"
   },
   "outputs": [],
   "source": [
    "def get_callback(model_name, patient):\n",
    "    ES = EarlyStopping(monitor = 'val_loss',\n",
    "                      patience = patient,\n",
    "                      mode = 'min',\n",
    "                      verbose = 1)\n",
    "    RR = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                          factor = 0.5,\n",
    "                          patience = patient / 2,\n",
    "                          min_lr = 0.000001,\n",
    "                          verbose = 1,\n",
    "                          mode = 'min')\n",
    "    MC = ModelCheckpoint(filepath = filepath,\n",
    "                        monitor = 'val_loss',\n",
    "                        verbose = 1, \n",
    "                        save_best_only = True,\n",
    "                        mode ='min')\n",
    "    return [ES,RR,MC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZoEhjudydFcI"
   },
   "outputs": [],
   "source": [
    "def get_model(model_name, iamge_size):\n",
    "    base_model = Xception(weights='imagenet', include_top=False)\n",
    "    #base_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(89, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    optimizer = optimizers.RMSprop(lr=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1283,
     "status": "ok",
     "timestamp": 1566888728164,
     "user": {
      "displayName": "김정훈",
      "photoUrl": "",
      "userId": "08418669037295379852"
     },
     "user_tz": -540
    },
    "id": "jwUG-AHudFcJ",
    "outputId": "d1b051be-dba0-451f-cc45-2b68a9e3d6a2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-75cde20eb881>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m train_generator = train_datagen.flow_from_dataframe(\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mdataframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTRAIN_IMG_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mx_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'img'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense,Dropout,Flatten,Activation, Conv2D, GlobalAveragePooling2D\n",
    "# Parameter\n",
    "#img_size = (224, 224)\n",
    "#nb_train_samples = len(X_train)\n",
    "#nb_validation_samples = len(X_val)\n",
    "#nb_test_samples = len(df_test)\n",
    "#epochs = 20\n",
    "#batch_size = 32\n",
    "\n",
    "# Define Generator config\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True, \n",
    "    vertical_flip = False,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode = 'nearest'\n",
    "    #preprocessing_function=preprocess_input)\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255\n",
    "#preprocessing_function=preprocess_input)\n",
    "                                )\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255\n",
    "#preprocessing_function=preprocess_input\n",
    "                                )\n",
    "# Make Generator\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=X_train, \n",
    "    directory=TRAIN_IMG_PATH,\n",
    "    x_col = 'img',\n",
    "    y_col = 'class',\n",
    "    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=16,\n",
    "    seed=42,\n",
    "    shuffle = True)\n",
    "    \n",
    "valid_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=X_val, \n",
    "    directory=VAL_IMG_PATH,\n",
    "    x_col = 'img',\n",
    "    y_col = 'class',\n",
    "    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=16,\n",
    "    shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14116,
     "status": "error",
     "timestamp": 1566888744130,
     "user": {
      "displayName": "김정훈",
      "photoUrl": "",
      "userId": "08418669037295379852"
     },
     "user_tz": -540
    },
    "id": "H0GcZaF5CVcU",
    "outputId": "f8fce675-3375-4de4-bcd4-96cf57fa7308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39256064/83683744 [=============>................] - ETA: 10 - ETA: 17:2 - ETA: 22:2 - ETA: 10:2 - ETA: 13:0 - ETA: 12:0 - ETA: 10:4 - ETA: 10:2 - ETA: 11:4 - ETA: 11:0 - ETA: 10:3 - ETA: 10:5 - ETA: 10:5 - ETA: 10:3 - ETA: 11:0 - ETA: 10:3 - ETA: 10:2 - ETA: 10:3 - ETA: 10:3 - ETA: 10:2 - ETA: 10:5 - ETA: 10:3 - ETA: 10:3 - ETA: 10:3 - ETA: 10:3 - ETA: 10:2 - ETA: 10:5 - ETA: 10:3 - ETA: 10:3 - ETA: 10:3 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:2 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:2 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:0 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:3 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:3 - ETA: 10:2 - ETA: 10:3 - ETA: 10:3 - ETA: 10:3 - ETA: 10:2 - ETA: 10:3 - ETA: 10:3 - ETA: 10:3 - ETA: 10:3 - ETA: 10:2 - ETA: 10:3 - ETA: 10:2 - ETA: 10:3 - ETA: 10:3 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:1 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:1 - ETA: 10:1 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:2 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:1 - ETA: 10:0 - ETA: 10:0 - ETA: 10:0 - ETA: 10:0 - ETA: 10:0 - ETA: 10:0 - ETA: 9:5 - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 9: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 8: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 7: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2:14"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78462976/83683744 [===========================>..] - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 59 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 51 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 49 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83689472/83683744 [==============================] - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 376s 4us/step\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, None, None, 2048)  20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 89)                91225     \n",
      "=================================================================\n",
      "Total params: 24,100,481\n",
      "Trainable params: 24,045,953\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_xception = get_model(Xception, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714969,
     "status": "ok",
     "timestamp": 1566849577282,
     "user": {
      "displayName": "장동근",
      "photoUrl": "",
      "userId": "04055126958846334883"
     },
     "user_tz": -540
    },
    "id": "s4Wc_j3ndFcT",
    "outputId": "8472f0cc-2963-40ee-c280-91945b5ed43d"
   },
   "outputs": [],
   "source": [
    "filepath = \"my_Xception_model_{val_acc:.2f}_{val_loss:.4f}.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714969,
     "status": "ok",
     "timestamp": 1566849577282,
     "user": {
      "displayName": "장동근",
      "photoUrl": "",
      "userId": "04055126958846334883"
     },
     "user_tz": -540
    },
    "id": "s4Wc_j3ndFcT",
    "outputId": "8472f0cc-2963-40ee-c280-91945b5ed43d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/34 [==============================] - 65s 2s/step - loss: 4.4875 - acc: 0.0143 - val_loss: 4.4409 - val_acc: 0.0670\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.44092, saving model to my_Xception_model_0.07_4.4409.h5\n",
      "Epoch 2/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 4.2390 - acc: 0.0714 - val_loss: 4.2553 - val_acc: 0.1285\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.44092 to 4.25531, saving model to my_Xception_model_0.13_4.2553.h5\n",
      "Epoch 3/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 3.7676 - acc: 0.1625 - val_loss: 3.8330 - val_acc: 0.1676\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.25531 to 3.83305, saving model to my_Xception_model_0.17_3.8330.h5\n",
      "Epoch 4/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 3.2747 - acc: 0.2572 - val_loss: 3.2999 - val_acc: 0.3128\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.83305 to 3.29995, saving model to my_Xception_model_0.31_3.2999.h5\n",
      "Epoch 5/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 2.6456 - acc: 0.4000 - val_loss: 2.8078 - val_acc: 0.3464\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.29995 to 2.80778, saving model to my_Xception_model_0.35_2.8078.h5\n",
      "Epoch 6/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 2.1859 - acc: 0.4679 - val_loss: 2.2874 - val_acc: 0.4581\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.80778 to 2.28744, saving model to my_Xception_model_0.46_2.2874.h5\n",
      "Epoch 7/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 1.7651 - acc: 0.5965 - val_loss: 1.8860 - val_acc: 0.5140\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.28744 to 1.88604, saving model to my_Xception_model_0.51_1.8860.h5\n",
      "Epoch 8/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 1.4145 - acc: 0.6553 - val_loss: 1.6279 - val_acc: 0.5754\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.88604 to 1.62787, saving model to my_Xception_model_0.58_1.6279.h5\n",
      "Epoch 9/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 1.0613 - acc: 0.7428 - val_loss: 1.4271 - val_acc: 0.6592\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.62787 to 1.42707, saving model to my_Xception_model_0.66_1.4271.h5\n",
      "Epoch 10/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.8376 - acc: 0.7964 - val_loss: 1.2234 - val_acc: 0.6704\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.42707 to 1.22336, saving model to my_Xception_model_0.67_1.2234.h5\n",
      "Epoch 11/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.6712 - acc: 0.8250 - val_loss: 1.1803 - val_acc: 0.6704\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.22336 to 1.18027, saving model to my_Xception_model_0.67_1.1803.h5\n",
      "Epoch 12/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.4860 - acc: 0.8857 - val_loss: 0.9829 - val_acc: 0.7542\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.18027 to 0.98289, saving model to my_Xception_model_0.75_0.9829.h5\n",
      "Epoch 13/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.3928 - acc: 0.9072 - val_loss: 0.9303 - val_acc: 0.7318\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.98289 to 0.93026, saving model to my_Xception_model_0.73_0.9303.h5\n",
      "Epoch 14/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.2929 - acc: 0.9286 - val_loss: 0.8843 - val_acc: 0.7821\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.93026 to 0.88429, saving model to my_Xception_model_0.78_0.8843.h5\n",
      "Epoch 15/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.2520 - acc: 0.9340 - val_loss: 0.8029 - val_acc: 0.7933\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.88429 to 0.80294, saving model to my_Xception_model_0.79_0.8029.h5\n",
      "Epoch 16/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.2110 - acc: 0.9553 - val_loss: 0.7219 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.80294 to 0.72188, saving model to my_Xception_model_0.81_0.7219.h5\n",
      "Epoch 17/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.1517 - acc: 0.9643 - val_loss: 0.8700 - val_acc: 0.8156\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.72188\n",
      "Epoch 18/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.1235 - acc: 0.9750 - val_loss: 0.8100 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.72188\n",
      "Epoch 19/100\n",
      "35/34 [==============================] - 52s 1s/step - loss: 0.1055 - acc: 0.9803 - val_loss: 0.6001 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.72188 to 0.60011, saving model to my_Xception_model_0.85_0.6001.h5\n",
      "Epoch 20/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0694 - acc: 0.9893 - val_loss: 0.6258 - val_acc: 0.8492\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.60011\n",
      "Epoch 21/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0420 - acc: 0.9893 - val_loss: 0.6250 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.60011\n",
      "Epoch 22/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0619 - acc: 0.9858 - val_loss: 0.5854 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.60011 to 0.58540, saving model to my_Xception_model_0.86_0.5854.h5\n",
      "Epoch 23/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0474 - acc: 0.9875 - val_loss: 0.5887 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.58540\n",
      "Epoch 24/100\n",
      "35/34 [==============================] - 52s 1s/step - loss: 0.0260 - acc: 0.9946 - val_loss: 0.5871 - val_acc: 0.8827\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.58540\n",
      "Epoch 25/100\n",
      "35/34 [==============================] - 52s 1s/step - loss: 0.0410 - acc: 0.9911 - val_loss: 0.5803 - val_acc: 0.8771\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.58540 to 0.58033, saving model to my_Xception_model_0.88_0.5803.h5\n",
      "Epoch 26/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0337 - acc: 0.9911 - val_loss: 0.5747 - val_acc: 0.8827\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.58033 to 0.57474, saving model to my_Xception_model_0.88_0.5747.h5\n",
      "Epoch 27/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0307 - acc: 0.9964 - val_loss: 0.5944 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.57474\n",
      "Epoch 28/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0243 - acc: 0.9947 - val_loss: 0.5920 - val_acc: 0.8771\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.57474\n",
      "Epoch 29/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0321 - acc: 0.9875 - val_loss: 0.5892 - val_acc: 0.8771\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.57474\n",
      "Epoch 30/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0436 - acc: 0.9859 - val_loss: 0.5930 - val_acc: 0.8771\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.57474\n",
      "Epoch 00030: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model_xception.fit_generator(train_generator,\n",
    "                                    steps_per_epoch = len(X_train.index) / BATCH_SIZE,\n",
    "                                    epochs = EPOCHS,\n",
    "                                    validation_data = valid_generator,\n",
    "                                    validation_steps = len(X_val.index) / BATCH_SIZE,\n",
    "                                    verbose = 1,\n",
    "                                    shuffle = False,\n",
    "                                    callbacks = get_callback(model_xception, 4)\n",
    "                                    )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nXpqvYPjdFcY"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-_pKADKdFcZ"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_8XhCeFdFcZ"
   },
   "outputs": [],
   "source": [
    "model_list = sorted([i for i in os.listdir() if \"my_\" in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1566849625935,
     "user": {
      "displayName": "장동근",
      "photoUrl": "",
      "userId": "04055126958846334883"
     },
     "user_tz": -540
    },
    "id": "Eqi4UjmsdFcb",
    "outputId": "65a07520-9f89-43ab-b2a2-3f6969ada51c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_Xception_model_0.06_4.4046.h5',\n",
       " 'my_Xception_model_0.07_4.4409.h5',\n",
       " 'my_Xception_model_0.13_4.2553.h5',\n",
       " 'my_Xception_model_0.15_4.1471.h5',\n",
       " 'my_Xception_model_0.17_3.8330.h5',\n",
       " 'my_Xception_model_0.21_3.6704.h5',\n",
       " 'my_Xception_model_0.28_3.1420.h5',\n",
       " 'my_Xception_model_0.31_3.2999.h5',\n",
       " 'my_Xception_model_0.35_2.8078.h5',\n",
       " 'my_Xception_model_0.39_2.2241.h5',\n",
       " 'my_Xception_model_0.41_2.6017.h5',\n",
       " 'my_Xception_model_0.46_2.2874.h5',\n",
       " 'my_Xception_model_0.51_1.8860.h5',\n",
       " 'my_Xception_model_0.54_1.8257.h5',\n",
       " 'my_Xception_model_0.58_1.6279.h5',\n",
       " 'my_Xception_model_0.61_1.4835.h5',\n",
       " 'my_Xception_model_0.65_1.2882.h5',\n",
       " 'my_Xception_model_0.66_1.2153.h5',\n",
       " 'my_Xception_model_0.66_1.4271.h5',\n",
       " 'my_Xception_model_0.67_1.1803.h5',\n",
       " 'my_Xception_model_0.67_1.2234.h5',\n",
       " 'my_Xception_model_0.69_0.9279.h5',\n",
       " 'my_Xception_model_0.73_0.9303.h5',\n",
       " 'my_Xception_model_0.73_0.9646.h5',\n",
       " 'my_Xception_model_0.73_1.0084.h5',\n",
       " 'my_Xception_model_0.74_1.1458.h5',\n",
       " 'my_Xception_model_0.75_0.9829.h5',\n",
       " 'my_Xception_model_0.78_0.8843.h5',\n",
       " 'my_Xception_model_0.79_0.7854.h5',\n",
       " 'my_Xception_model_0.79_0.8029.h5',\n",
       " 'my_Xception_model_0.81_0.7219.h5',\n",
       " 'my_Xception_model_0.82_0.6885.h5',\n",
       " 'my_Xception_model_0.83_0.7946.h5',\n",
       " 'my_Xception_model_0.84_0.6490.h5',\n",
       " 'my_Xception_model_0.84_0.6832.h5',\n",
       " 'my_Xception_model_0.85_0.6001.h5',\n",
       " 'my_Xception_model_0.86_0.5854.h5',\n",
       " 'my_Xception_model_0.88_0.5747.h5',\n",
       " 'my_Xception_model_0.88_0.5803.h5']"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJzxzljvp-DJ"
   },
   "outputs": [],
   "source": [
    "model_xception.save_weights('/gdrive/My Drive/Colab Notebooks/model/model_xception_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_DenseNet121_model_0.82_0.7317.h5',\n",
       " 'my_ResNet50_model_0.87_0.7278.h5',\n",
       " 'my_Xception_model_0.88_0.6905.h5',\n",
       " 'my_Xception_model_1_0.82_0.5864.h5',\n",
       " 'my_Xception_model_2_0.84_0.6394.h5']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = os.listdir('./model/')\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z99UtpJhdFcc"
   },
   "outputs": [],
   "source": [
    "model_xception.load_weights('./model/' + model_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrRLJq17UnDg"
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "def get_RESNET_model(model_name, iamge_size):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    #base_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(89, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    optimizer = optimizers.RMSprop(lr=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18363,
     "status": "ok",
     "timestamp": 1566849904752,
     "user": {
      "displayName": "장동근",
      "photoUrl": "",
      "userId": "04055126958846334883"
     },
     "user_tz": -540
    },
    "id": "AVjbm2vyhuzw",
    "outputId": "9fb3731d-bf45-42ee-e50a-8f40c6db09d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, None, None, 2048)  20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 89)                91225     \n",
      "=================================================================\n",
      "Total params: 24,100,481\n",
      "Trainable params: 24,045,953\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ResNet = get_model(ResNet50, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1528023,
     "status": "error",
     "timestamp": 1566851460353,
     "user": {
      "displayName": "장동근",
      "photoUrl": "",
      "userId": "04055126958846334883"
     },
     "user_tz": -540
    },
    "id": "FwoJ-8_Thhzm",
    "outputId": "54236649-fc15-4de0-9a6e-6387202b8609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/34 [==============================] - 68s 2s/step - loss: 4.4614 - acc: 0.0179 - val_loss: 4.4093 - val_acc: 0.0726\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.40931, saving model to my_ResNet50_model_0.07_4.4093.h5\n",
      "Epoch 2/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 4.2298 - acc: 0.1000 - val_loss: 4.1934 - val_acc: 0.0894\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.40931 to 4.19342, saving model to my_ResNet50_model_0.09_4.1934.h5\n",
      "Epoch 3/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 3.7998 - acc: 0.2000 - val_loss: 3.8264 - val_acc: 0.2011\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.19342 to 3.82642, saving model to my_ResNet50_model_0.20_3.8264.h5\n",
      "Epoch 4/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 3.1747 - acc: 0.2876 - val_loss: 3.3294 - val_acc: 0.2626\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.82642 to 3.32944, saving model to my_ResNet50_model_0.26_3.3294.h5\n",
      "Epoch 5/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 2.7022 - acc: 0.3643 - val_loss: 2.7579 - val_acc: 0.3352\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.32944 to 2.75787, saving model to my_ResNet50_model_0.34_2.7579.h5\n",
      "Epoch 6/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 2.1368 - acc: 0.4750 - val_loss: 2.2329 - val_acc: 0.4413\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.75787 to 2.23288, saving model to my_ResNet50_model_0.44_2.2329.h5\n",
      "Epoch 7/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 1.7465 - acc: 0.5732 - val_loss: 1.8210 - val_acc: 0.5140\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.23288 to 1.82098, saving model to my_ResNet50_model_0.51_1.8210.h5\n",
      "Epoch 8/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 1.3555 - acc: 0.6606 - val_loss: 1.6565 - val_acc: 0.5251\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.82098 to 1.65648, saving model to my_ResNet50_model_0.53_1.6565.h5\n",
      "Epoch 9/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 1.0672 - acc: 0.7249 - val_loss: 1.3944 - val_acc: 0.6201\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.65648 to 1.39436, saving model to my_ResNet50_model_0.62_1.3944.h5\n",
      "Epoch 10/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.8258 - acc: 0.7964 - val_loss: 1.1934 - val_acc: 0.6816\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.39436 to 1.19342, saving model to my_ResNet50_model_0.68_1.1934.h5\n",
      "Epoch 11/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.6214 - acc: 0.8590 - val_loss: 1.0636 - val_acc: 0.7095\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.19342 to 1.06356, saving model to my_ResNet50_model_0.71_1.0636.h5\n",
      "Epoch 12/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.4715 - acc: 0.8787 - val_loss: 0.9796 - val_acc: 0.7542\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.06356 to 0.97957, saving model to my_ResNet50_model_0.75_0.9796.h5\n",
      "Epoch 13/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.3548 - acc: 0.9036 - val_loss: 0.9496 - val_acc: 0.7318\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.97957 to 0.94964, saving model to my_ResNet50_model_0.73_0.9496.h5\n",
      "Epoch 14/100\n",
      "35/34 [==============================] - 50s 1s/step - loss: 0.3390 - acc: 0.9073 - val_loss: 0.7745 - val_acc: 0.7765\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.94964 to 0.77447, saving model to my_ResNet50_model_0.78_0.7745.h5\n",
      "Epoch 15/100\n",
      "35/34 [==============================] - 50s 1s/step - loss: 0.2536 - acc: 0.9232 - val_loss: 0.7881 - val_acc: 0.7989\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.77447\n",
      "Epoch 16/100\n",
      "35/34 [==============================] - 50s 1s/step - loss: 0.1879 - acc: 0.9571 - val_loss: 0.7079 - val_acc: 0.8324\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.77447 to 0.70789, saving model to my_ResNet50_model_0.83_0.7079.h5\n",
      "Epoch 17/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.1604 - acc: 0.9536 - val_loss: 0.8050 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.70789\n",
      "Epoch 18/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.1427 - acc: 0.9696 - val_loss: 0.6796 - val_acc: 0.8156\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.70789 to 0.67955, saving model to my_ResNet50_model_0.82_0.6796.h5\n",
      "Epoch 19/100\n",
      "35/34 [==============================] - 50s 1s/step - loss: 0.1235 - acc: 0.9786 - val_loss: 0.8547 - val_acc: 0.7877\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.67955\n",
      "Epoch 20/100\n",
      "35/34 [==============================] - 50s 1s/step - loss: 0.0730 - acc: 0.9821 - val_loss: 0.7559 - val_acc: 0.7933\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.67955\n",
      "Epoch 21/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0710 - acc: 0.9804 - val_loss: 0.6712 - val_acc: 0.8268\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.67955 to 0.67124, saving model to my_ResNet50_model_0.83_0.6712.h5\n",
      "Epoch 22/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0446 - acc: 0.9946 - val_loss: 0.7427 - val_acc: 0.8212\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.67124\n",
      "Epoch 23/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0443 - acc: 0.9875 - val_loss: 0.7231 - val_acc: 0.8156\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.67124\n",
      "Epoch 24/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0384 - acc: 0.9893 - val_loss: 0.6460 - val_acc: 0.8156\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.67124 to 0.64604, saving model to my_ResNet50_model_0.82_0.6460.h5\n",
      "Epoch 25/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0451 - acc: 0.9893 - val_loss: 0.6197 - val_acc: 0.8324\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.64604 to 0.61973, saving model to my_ResNet50_model_0.83_0.6197.h5\n",
      "Epoch 26/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0256 - acc: 0.9929 - val_loss: 0.6294 - val_acc: 0.8324\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.61973\n",
      "Epoch 27/100\n",
      "35/34 [==============================] - 51s 1s/step - loss: 0.0308 - acc: 0.9911 - val_loss: 0.6029 - val_acc: 0.8380\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.61973 to 0.60289, saving model to my_ResNet50_model_0.84_0.6029.h5\n",
      "Epoch 28/100\n",
      "35/34 [==============================] - 50s 1s/step - loss: 0.0298 - acc: 0.9929 - val_loss: 0.5520 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.60289 to 0.55200, saving model to my_ResNet50_model_0.86_0.5520.h5\n",
      "Epoch 29/100\n",
      "35/34 [==============================] - 50s 1s/step - loss: 0.0194 - acc: 0.9946 - val_loss: 0.6733 - val_acc: 0.8324\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.55200\n",
      "Epoch 30/100\n",
      " 4/34 [==>...........................] - ETA: 40s - loss: 0.0329 - acc: 0.9844"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-e55401b0afe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                                     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ResNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                                     )\n\u001b[1;32m     12\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath = \"my_ResNet50_model_{val_acc:.2f}_{val_loss:.4f}.h5\"\n",
    "\n",
    "history = model_ResNet.fit_generator(train_generator,\n",
    "                                    steps_per_epoch = len(X_train.index) / BATCH_SIZE,\n",
    "                                    epochs = EPOCHS,\n",
    "                                    validation_data = valid_generator,\n",
    "                                    validation_steps = len(X_val.index) / BATCH_SIZE,\n",
    "                                    verbose = 1,\n",
    "                                    shuffle = False,\n",
    "                                    callbacks = get_callback(model_ResNet, 4)\n",
    "                                    )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXdi-pD9psyC"
   },
   "outputs": [],
   "source": [
    "model_ResNet.save_weights('/gdrive/My Drive/Colab Notebooks/model/ResNetbest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsrTRn0jfVpH"
   },
   "outputs": [],
   "source": [
    "from keras.applications.densenet import DenseNet121\n",
    "def get_DenseNet121_model(model_name, iamge_size):\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False)\n",
    "    #base_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(89, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    optimizer = optimizers.RMSprop(lr=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47226,
     "status": "ok",
     "timestamp": 1566857699745,
     "user": {
      "displayName": "장동근",
      "photoUrl": "",
      "userId": "04055126958846334883"
     },
     "user_tz": -540
    },
    "id": "G02UHTIc-uYr",
    "outputId": "53d36a06-f8d7-4039-9644-6b0ba0cb72f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 22:14:14.449270 140132891797376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 0s 0us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, None, None, 1024)  7037504   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 89)                91225     \n",
      "=================================================================\n",
      "Total params: 9,227,929\n",
      "Trainable params: 9,144,281\n",
      "Non-trainable params: 83,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_DenseNet121 = get_DenseNet121_model(DenseNet121, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 860761,
     "status": "ok",
     "timestamp": 1566858593128,
     "user": {
      "displayName": "장동근",
      "photoUrl": "",
      "userId": "04055126958846334883"
     },
     "user_tz": -540
    },
    "id": "b665hhS0-nGt",
    "outputId": "66c28da3-527e-4b39-dc9a-84ec412bf95e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/34 [==============================] - 76s 2s/step - loss: 4.5433 - acc: 0.0214 - val_loss: 4.4221 - val_acc: 0.0335\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.42209, saving model to my_DenseNet121_model_0.03_4.4221.h5\n",
      "Epoch 2/100\n",
      "35/34 [==============================] - 31s 894ms/step - loss: 4.2003 - acc: 0.0857 - val_loss: 3.9879 - val_acc: 0.1508\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.42209 to 3.98785, saving model to my_DenseNet121_model_0.15_3.9879.h5\n",
      "Epoch 3/100\n",
      "35/34 [==============================] - 32s 900ms/step - loss: 3.7598 - acc: 0.1285 - val_loss: 3.7328 - val_acc: 0.1341\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.98785 to 3.73282, saving model to my_DenseNet121_model_0.13_3.7328.h5\n",
      "Epoch 4/100\n",
      "35/34 [==============================] - 32s 901ms/step - loss: 3.3173 - acc: 0.2197 - val_loss: 3.3520 - val_acc: 0.2011\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.73282 to 3.35202, saving model to my_DenseNet121_model_0.20_3.3520.h5\n",
      "Epoch 5/100\n",
      "35/34 [==============================] - 32s 901ms/step - loss: 2.7862 - acc: 0.3358 - val_loss: 2.6912 - val_acc: 0.3296\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.35202 to 2.69118, saving model to my_DenseNet121_model_0.33_2.6912.h5\n",
      "Epoch 6/100\n",
      "35/34 [==============================] - 33s 932ms/step - loss: 2.3252 - acc: 0.3983 - val_loss: 2.2183 - val_acc: 0.4190\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.69118 to 2.21834, saving model to my_DenseNet121_model_0.42_2.2183.h5\n",
      "Epoch 7/100\n",
      "35/34 [==============================] - 33s 936ms/step - loss: 1.9763 - acc: 0.4964 - val_loss: 2.2545 - val_acc: 0.4413\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.21834\n",
      "Epoch 8/100\n",
      "35/34 [==============================] - 33s 935ms/step - loss: 1.6068 - acc: 0.5679 - val_loss: 1.8483 - val_acc: 0.5084\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.21834 to 1.84827, saving model to my_DenseNet121_model_0.51_1.8483.h5\n",
      "Epoch 9/100\n",
      "35/34 [==============================] - 32s 925ms/step - loss: 1.4415 - acc: 0.6232 - val_loss: 1.6039 - val_acc: 0.5754\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.84827 to 1.60393, saving model to my_DenseNet121_model_0.58_1.6039.h5\n",
      "Epoch 10/100\n",
      "35/34 [==============================] - 32s 925ms/step - loss: 1.0943 - acc: 0.7214 - val_loss: 1.5096 - val_acc: 0.6034\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.60393 to 1.50957, saving model to my_DenseNet121_model_0.60_1.5096.h5\n",
      "Epoch 11/100\n",
      "35/34 [==============================] - 32s 926ms/step - loss: 0.9944 - acc: 0.7179 - val_loss: 1.5084 - val_acc: 0.5642\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.50957 to 1.50837, saving model to my_DenseNet121_model_0.56_1.5084.h5\n",
      "Epoch 12/100\n",
      "35/34 [==============================] - 33s 930ms/step - loss: 0.7749 - acc: 0.7893 - val_loss: 1.1244 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.50837 to 1.12442, saving model to my_DenseNet121_model_0.69_1.1244.h5\n",
      "Epoch 13/100\n",
      "35/34 [==============================] - 33s 933ms/step - loss: 0.6413 - acc: 0.8270 - val_loss: 1.0775 - val_acc: 0.7151\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.12442 to 1.07753, saving model to my_DenseNet121_model_0.72_1.0775.h5\n",
      "Epoch 14/100\n",
      "35/34 [==============================] - 31s 895ms/step - loss: 0.5472 - acc: 0.8520 - val_loss: 1.2143 - val_acc: 0.7207\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.07753\n",
      "Epoch 15/100\n",
      "35/34 [==============================] - 32s 902ms/step - loss: 0.4991 - acc: 0.8537 - val_loss: 0.9501 - val_acc: 0.7598\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.07753 to 0.95006, saving model to my_DenseNet121_model_0.76_0.9501.h5\n",
      "Epoch 16/100\n",
      "35/34 [==============================] - 33s 939ms/step - loss: 0.3756 - acc: 0.9017 - val_loss: 1.4104 - val_acc: 0.6704\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.95006\n",
      "Epoch 17/100\n",
      "35/34 [==============================] - 32s 928ms/step - loss: 0.3968 - acc: 0.8893 - val_loss: 1.2247 - val_acc: 0.7318\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.95006\n",
      "Epoch 18/100\n",
      "35/34 [==============================] - 32s 921ms/step - loss: 0.2267 - acc: 0.9500 - val_loss: 1.1515 - val_acc: 0.7486\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.95006\n",
      "Epoch 19/100\n",
      "35/34 [==============================] - 33s 933ms/step - loss: 0.1789 - acc: 0.9553 - val_loss: 0.9062 - val_acc: 0.7765\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.95006 to 0.90617, saving model to my_DenseNet121_model_0.78_0.9062.h5\n",
      "Epoch 20/100\n",
      "35/34 [==============================] - 32s 927ms/step - loss: 0.1526 - acc: 0.9643 - val_loss: 0.7341 - val_acc: 0.8045\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.90617 to 0.73405, saving model to my_DenseNet121_model_0.80_0.7341.h5\n",
      "Epoch 21/100\n",
      "35/34 [==============================] - 33s 934ms/step - loss: 0.1718 - acc: 0.9554 - val_loss: 0.9433 - val_acc: 0.7821\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.73405\n",
      "Epoch 22/100\n",
      "35/34 [==============================] - 32s 904ms/step - loss: 0.1418 - acc: 0.9678 - val_loss: 0.8664 - val_acc: 0.7598\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.73405\n",
      "Epoch 23/100\n",
      "35/34 [==============================] - 31s 898ms/step - loss: 0.0942 - acc: 0.9857 - val_loss: 0.8920 - val_acc: 0.8380\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.73405\n",
      "Epoch 24/100\n",
      "35/34 [==============================] - 33s 929ms/step - loss: 0.0932 - acc: 0.9786 - val_loss: 0.7432 - val_acc: 0.8380\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.73405\n",
      "Epoch 00024: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 178,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"my_DenseNet121_model_{val_acc:.2f}_{val_loss:.4f}.h5\"\n",
    "\n",
    "history = model_DenseNet121.fit_generator(train_generator,\n",
    "                                    steps_per_epoch = len(X_train.index) / BATCH_SIZE,\n",
    "                                    epochs = EPOCHS,\n",
    "                                    validation_data = valid_generator,\n",
    "                                    validation_steps = len(X_val.index) / BATCH_SIZE,\n",
    "                                    verbose = 1,\n",
    "                                    shuffle = False,\n",
    "                                    callbacks = get_callback(model_DenseNet121, 4)\n",
    "                                    )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whVFtI6qAKUK"
   },
   "outputs": [],
   "source": [
    "model_DenseNet121.save_weights('/gdrive/My Drive/Colab Notebooks/model/DenseNetbest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IY2csLBEkyPx"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "TEST_IMG_PATH = os.path.join(DATA_PATH,'test_img')\n",
    "if set(list(df_test.img)) == set(os.listdir(TEST_IMG_PATH)) :\n",
    "    print(\"Test file 누락 없음!\")\n",
    "else : \n",
    "    print(\"Test file 누락\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lK8S6Yupk06u"
   },
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = df_test,\n",
    "    directory = TEST_IMG_PATH,\n",
    "    x_col = 'img',\n",
    "    y_col = None,\n",
    "    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = None,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6170,
     "status": "ok",
     "timestamp": 1566851503943,
     "user": {
      "displayName": "장동근",
      "photoUrl": "",
      "userId": "04055126958846334883"
     },
     "user_tz": -540
    },
    "id": "Abzhl83Ok8Bc",
    "outputId": "eb151604-56d5-47c4-d8e9-6bfc3e4b73bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/0 [========================================] - 5s 5s/step\n",
      "CPU times: user 4.61 s, sys: 197 ms, total: 4.81 s\n",
      "Wall time: 4.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_generator.reset()\n",
    "prediction = model_ResNet.predict_generator(\n",
    "    generator = test_generator,\n",
    "    steps = len(df_test)/BATCH_SIZE,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvLphNhNk-08"
   },
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(prediction, axis=1)\n",
    "\n",
    "# Generator class dictionary mapping\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "#submission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\n",
    "#submission[\"class\"] = predictions\n",
    "#submission.to_csv(\"submission.csv\", index=False)\n",
    "#submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gofDBHMooKFV"
   },
   "outputs": [],
   "source": [
    "df_test['prediction'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 678,
     "status": "ok",
     "timestamp": 1566851549052,
     "user": {
      "displayName": "장동근",
      "photoUrl": "",
      "userId": "04055126958846334883"
     },
     "user_tz": -540
    },
    "id": "zZOtu2RYoLOy",
    "outputId": "9d28e800-d1c6-4f40-cf5a-85cbbaa97751"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>img</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>650700520</td>\n",
       "      <td>0.jpeg</td>\n",
       "      <td>644700140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>643504310</td>\n",
       "      <td>1.jpeg</td>\n",
       "      <td>643504310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>645403740</td>\n",
       "      <td>2.jpeg</td>\n",
       "      <td>645403740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>649900060</td>\n",
       "      <td>3.jpeg</td>\n",
       "      <td>641601880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>644700140</td>\n",
       "      <td>4.jpeg</td>\n",
       "      <td>645301210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645301210</td>\n",
       "      <td>5.jpeg</td>\n",
       "      <td>647802630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>644902890</td>\n",
       "      <td>6.jpeg</td>\n",
       "      <td>644900310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>642202020</td>\n",
       "      <td>7.jpeg</td>\n",
       "      <td>642200220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>641905450</td>\n",
       "      <td>8.jpeg</td>\n",
       "      <td>653600010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>641602000</td>\n",
       "      <td>9.jpeg</td>\n",
       "      <td>643304610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>642200220</td>\n",
       "      <td>10.jpeg</td>\n",
       "      <td>642200220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>641602040</td>\n",
       "      <td>11.jpeg</td>\n",
       "      <td>641602040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class      img prediction\n",
       "0   650700520   0.jpeg  644700140\n",
       "1   643504310   1.jpeg  643504310\n",
       "2   645403740   2.jpeg  645403740\n",
       "3   649900060   3.jpeg  641601880\n",
       "4   644700140   4.jpeg  645301210\n",
       "5   645301210   5.jpeg  647802630\n",
       "6   644902890   6.jpeg  644900310\n",
       "7   642202020   7.jpeg  642200220\n",
       "8   641905450   8.jpeg  653600010\n",
       "9   641602000   9.jpeg  643304610\n",
       "10  642200220  10.jpeg  642200220\n",
       "11  641602040  11.jpeg  641602040"
      ]
     },
     "execution_count": 144,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uh0RmvoIoQLN"
   },
   "outputs": [],
   "source": [
    "model_list = sorted([i for i in os.listdir() if \"my_\" in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4TaCtK1do4Ds"
   },
   "outputs": [],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 682,
     "status": "error",
     "timestamp": 1566851875328,
     "user": {
      "displayName": "장동근",
      "photoUrl": "",
      "userId": "04055126958846334883"
     },
     "user_tz": -540
    },
    "id": "OAVbIczBo4sJ",
    "outputId": "9baace43-838e-4914-e7d5-410acfe9665e"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-4799265a33da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gdrive/My Drive/Colab Notebooks/model/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'save_weights'"
     ]
    }
   ],
   "source": [
    "for i in model_list:\n",
    "  i.save_weights('/gdrive/My Drive/Colab Notebooks/model/'+i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(directory, resize_to=(299,299)):\n",
    "    images = []\n",
    "    \n",
    "    for f in tqdm(os.listdir(directory)):         #tqdm: progress bar 표시\n",
    "        \n",
    "        #디렉토리 이름과 파일 이름을 연결.\n",
    "        #directory: ./cats_dogs/train/\n",
    "        #f: cat.0.jpg\n",
    "        #path: ./cats_dogs/train/cat.0.jpg\n",
    "        path = os.path.join(directory, f)\n",
    "        \n",
    "        im = Image.open(path)\n",
    "        im = im.resize(resize_to)\n",
    "        \n",
    "        im = np.array(im) / 255.0   # 이미지 파일에 저장된 RGB 값은 0~255 사이로 저장되어 있음.ㅁ\n",
    "        im = im.astype('float32')\n",
    "        \n",
    "        images.append(im)  # images에 im 추가\n",
    "    \n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.85490197, 0.8627451 , 0.8509804 ],\n",
       "         [0.85490197, 0.8627451 , 0.8509804 ],\n",
       "         [0.85490197, 0.8627451 , 0.8509804 ],\n",
       "         ...,\n",
       "         [0.84313726, 0.8509804 , 0.8392157 ],\n",
       "         [0.84313726, 0.8509804 , 0.8392157 ],\n",
       "         [0.84705883, 0.85490197, 0.84313726]],\n",
       "\n",
       "        [[0.8509804 , 0.85882354, 0.84705883],\n",
       "         [0.8509804 , 0.85882354, 0.84705883],\n",
       "         [0.85490197, 0.8627451 , 0.8509804 ],\n",
       "         ...,\n",
       "         [0.84313726, 0.8509804 , 0.8392157 ],\n",
       "         [0.84313726, 0.8509804 , 0.8392157 ],\n",
       "         [0.85490197, 0.8627451 , 0.8509804 ]],\n",
       "\n",
       "        [[0.8509804 , 0.85882354, 0.84705883],\n",
       "         [0.84705883, 0.85490197, 0.84313726],\n",
       "         [0.84705883, 0.85490197, 0.84313726],\n",
       "         ...,\n",
       "         [0.8509804 , 0.8509804 , 0.8509804 ],\n",
       "         [0.85490197, 0.8627451 , 0.85882354],\n",
       "         [0.87058824, 0.8784314 , 0.8666667 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8627451 , 0.87058824, 0.85882354],\n",
       "         [0.84313726, 0.8509804 , 0.8392157 ],\n",
       "         [0.84313726, 0.8509804 , 0.8392157 ],\n",
       "         ...,\n",
       "         [0.83137256, 0.8392157 , 0.827451  ],\n",
       "         [0.8392157 , 0.84705883, 0.8352941 ],\n",
       "         [0.83137256, 0.8392157 , 0.827451  ]],\n",
       "\n",
       "        [[0.85882354, 0.8666667 , 0.85490197],\n",
       "         [0.84313726, 0.84313726, 0.8352941 ],\n",
       "         [0.84313726, 0.84313726, 0.8352941 ],\n",
       "         ...,\n",
       "         [0.8392157 , 0.84705883, 0.8352941 ],\n",
       "         [0.8352941 , 0.84313726, 0.83137256],\n",
       "         [0.84313726, 0.8509804 , 0.8392157 ]],\n",
       "\n",
       "        [[0.85882354, 0.85882354, 0.8509804 ],\n",
       "         [0.84313726, 0.8509804 , 0.8392157 ],\n",
       "         [0.84705883, 0.84705883, 0.8392157 ],\n",
       "         ...,\n",
       "         [0.8352941 , 0.84313726, 0.83137256],\n",
       "         [0.84313726, 0.8509804 , 0.8392157 ],\n",
       "         [0.85490197, 0.8627451 , 0.8509804 ]]],\n",
       "\n",
       "\n",
       "       [[[0.84705883, 0.85490197, 0.84313726],\n",
       "         [0.8509804 , 0.85882354, 0.84705883],\n",
       "         [0.84705883, 0.85490197, 0.84313726],\n",
       "         ...,\n",
       "         [0.84313726, 0.84313726, 0.8352941 ],\n",
       "         [0.84313726, 0.84313726, 0.8352941 ],\n",
       "         [0.84313726, 0.84313726, 0.8352941 ]],\n",
       "\n",
       "        [[0.8509804 , 0.85882354, 0.84705883],\n",
       "         [0.8392157 , 0.84705883, 0.8352941 ],\n",
       "         [0.8509804 , 0.85882354, 0.84705883],\n",
       "         ...,\n",
       "         [0.8392157 , 0.84705883, 0.8352941 ],\n",
       "         [0.84705883, 0.84705883, 0.8392157 ],\n",
       "         [0.85490197, 0.85490197, 0.84705883]],\n",
       "\n",
       "        [[0.85490197, 0.8627451 , 0.8509804 ],\n",
       "         [0.84705883, 0.85490197, 0.84313726],\n",
       "         [0.85882354, 0.8666667 , 0.85490197],\n",
       "         ...,\n",
       "         [0.84705883, 0.84705883, 0.8392157 ],\n",
       "         [0.85490197, 0.85490197, 0.84705883],\n",
       "         [0.85490197, 0.85490197, 0.84705883]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8509804 , 0.85882354, 0.84705883],\n",
       "         [0.8352941 , 0.84313726, 0.83137256],\n",
       "         [0.84705883, 0.85490197, 0.84313726],\n",
       "         ...,\n",
       "         [0.8352941 , 0.84313726, 0.83137256],\n",
       "         [0.8235294 , 0.83137256, 0.81960785],\n",
       "         [0.827451  , 0.8352941 , 0.8235294 ]],\n",
       "\n",
       "        [[0.84313726, 0.8509804 , 0.8392157 ],\n",
       "         [0.84313726, 0.8509804 , 0.8392157 ],\n",
       "         [0.84705883, 0.84705883, 0.8392157 ],\n",
       "         ...,\n",
       "         [0.8392157 , 0.84705883, 0.8352941 ],\n",
       "         [0.827451  , 0.8352941 , 0.8235294 ],\n",
       "         [0.827451  , 0.8352941 , 0.8235294 ]],\n",
       "\n",
       "        [[0.84705883, 0.85490197, 0.84313726],\n",
       "         [0.8509804 , 0.85882354, 0.84705883],\n",
       "         [0.84705883, 0.84705883, 0.8392157 ],\n",
       "         ...,\n",
       "         [0.8392157 , 0.84705883, 0.8352941 ],\n",
       "         [0.84313726, 0.8509804 , 0.8392157 ],\n",
       "         [0.83137256, 0.8392157 , 0.827451  ]]],\n",
       "\n",
       "\n",
       "       [[[0.85882354, 0.8666667 , 0.85490197],\n",
       "         [0.87058824, 0.8784314 , 0.8666667 ],\n",
       "         [0.87058824, 0.8784314 , 0.8666667 ],\n",
       "         ...,\n",
       "         [0.8392157 , 0.84705883, 0.84313726],\n",
       "         [0.84313726, 0.8509804 , 0.84705883],\n",
       "         [0.84705883, 0.85490197, 0.8509804 ]],\n",
       "\n",
       "        [[0.8627451 , 0.87058824, 0.85882354],\n",
       "         [0.8745098 , 0.88235295, 0.87058824],\n",
       "         [0.8666667 , 0.8745098 , 0.8627451 ],\n",
       "         ...,\n",
       "         [0.8352941 , 0.84313726, 0.8392157 ],\n",
       "         [0.8509804 , 0.85882354, 0.85490197],\n",
       "         [0.85882354, 0.8666667 , 0.8627451 ]],\n",
       "\n",
       "        [[0.85490197, 0.8627451 , 0.8509804 ],\n",
       "         [0.8666667 , 0.8745098 , 0.8627451 ],\n",
       "         [0.8627451 , 0.87058824, 0.85882354],\n",
       "         ...,\n",
       "         [0.84313726, 0.8509804 , 0.84705883],\n",
       "         [0.8509804 , 0.85882354, 0.85490197],\n",
       "         [0.8627451 , 0.87058824, 0.8666667 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8392157 , 0.8392157 , 0.83137256],\n",
       "         [0.827451  , 0.8352941 , 0.8235294 ],\n",
       "         [0.8509804 , 0.85882354, 0.84705883],\n",
       "         ...,\n",
       "         [0.84313726, 0.84313726, 0.8352941 ],\n",
       "         [0.84313726, 0.84313726, 0.8352941 ],\n",
       "         [0.827451  , 0.8352941 , 0.8235294 ]],\n",
       "\n",
       "        [[0.84313726, 0.84313726, 0.8352941 ],\n",
       "         [0.84313726, 0.8509804 , 0.8392157 ],\n",
       "         [0.84705883, 0.85490197, 0.84313726],\n",
       "         ...,\n",
       "         [0.8509804 , 0.8509804 , 0.84313726],\n",
       "         [0.81960785, 0.827451  , 0.8156863 ],\n",
       "         [0.83137256, 0.83137256, 0.8235294 ]],\n",
       "\n",
       "        [[0.8392157 , 0.84705883, 0.8352941 ],\n",
       "         [0.85490197, 0.8627451 , 0.8509804 ],\n",
       "         [0.8666667 , 0.8745098 , 0.8627451 ],\n",
       "         ...,\n",
       "         [0.84313726, 0.84313726, 0.8352941 ],\n",
       "         [0.827451  , 0.8352941 , 0.8235294 ],\n",
       "         [0.84313726, 0.84313726, 0.8352941 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.83137256, 0.8       , 0.41568628],\n",
       "         [0.83137256, 0.8       , 0.41568628],\n",
       "         [0.83137256, 0.8       , 0.41568628],\n",
       "         ...,\n",
       "         [0.91764706, 0.9137255 , 0.49019608],\n",
       "         [0.91764706, 0.9137255 , 0.49019608],\n",
       "         [0.91764706, 0.9137255 , 0.49019608]],\n",
       "\n",
       "        [[0.83137256, 0.8       , 0.41568628],\n",
       "         [0.83137256, 0.8       , 0.41568628],\n",
       "         [0.83137256, 0.8       , 0.41568628],\n",
       "         ...,\n",
       "         [0.91764706, 0.9137255 , 0.49019608],\n",
       "         [0.91764706, 0.9137255 , 0.49019608],\n",
       "         [0.91764706, 0.9137255 , 0.49019608]],\n",
       "\n",
       "        [[0.83137256, 0.8       , 0.41568628],\n",
       "         [0.83137256, 0.8       , 0.41568628],\n",
       "         [0.83137256, 0.8       , 0.41568628],\n",
       "         ...,\n",
       "         [0.91764706, 0.9137255 , 0.49019608],\n",
       "         [0.91764706, 0.9137255 , 0.49019608],\n",
       "         [0.91764706, 0.9137255 , 0.49019608]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8156863 , 0.7764706 , 0.40392157],\n",
       "         [0.8156863 , 0.7764706 , 0.40392157],\n",
       "         [0.8156863 , 0.7764706 , 0.40392157],\n",
       "         ...,\n",
       "         [0.91764706, 0.9137255 , 0.49019608],\n",
       "         [0.91764706, 0.9137255 , 0.49019608],\n",
       "         [0.91764706, 0.9137255 , 0.49019608]],\n",
       "\n",
       "        [[0.8156863 , 0.7764706 , 0.40392157],\n",
       "         [0.8156863 , 0.7764706 , 0.40392157],\n",
       "         [0.8156863 , 0.7764706 , 0.40392157],\n",
       "         ...,\n",
       "         [0.91764706, 0.9137255 , 0.49019608],\n",
       "         [0.91764706, 0.9137255 , 0.49019608],\n",
       "         [0.91764706, 0.9137255 , 0.49019608]],\n",
       "\n",
       "        [[0.8156863 , 0.7764706 , 0.40392157],\n",
       "         [0.8156863 , 0.7764706 , 0.40392157],\n",
       "         [0.8156863 , 0.7764706 , 0.40392157],\n",
       "         ...,\n",
       "         [0.91764706, 0.9137255 , 0.49019608],\n",
       "         [0.91764706, 0.9137255 , 0.49019608],\n",
       "         [0.91764706, 0.9137255 , 0.49019608]]],\n",
       "\n",
       "\n",
       "       [[[0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         ...,\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177]],\n",
       "\n",
       "        [[0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         ...,\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177]],\n",
       "\n",
       "        [[0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         ...,\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6313726 , 0.7764706 , 0.88235295],\n",
       "         [0.6313726 , 0.7764706 , 0.88235295],\n",
       "         [0.6313726 , 0.7764706 , 0.88235295],\n",
       "         ...,\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177]],\n",
       "\n",
       "        [[0.6313726 , 0.7764706 , 0.8901961 ],\n",
       "         [0.6313726 , 0.7764706 , 0.8901961 ],\n",
       "         [0.6313726 , 0.7764706 , 0.8901961 ],\n",
       "         ...,\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177]],\n",
       "\n",
       "        [[0.6313726 , 0.7764706 , 0.8901961 ],\n",
       "         [0.6313726 , 0.7764706 , 0.8901961 ],\n",
       "         [0.6313726 , 0.7764706 , 0.8901961 ],\n",
       "         ...,\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177],\n",
       "         [0.65882355, 0.83137256, 0.92941177]]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = read_images(directory='./test/')\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0kuRMmmpj8J",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 26, 26, 26, 62, 26, 62, 26, 26, 26], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xception.predict_classes(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 26, 26, 26, 62, 26, 62], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model_xception.predict(images), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5651643e-03, 2.3887548e-04, 2.6659430e-03, 3.0391588e-04,\n",
       "        7.7882933e-04, 8.3184605e-05, 1.1570542e-03, 4.3708243e-04,\n",
       "        1.6959604e-03, 8.4924661e-03, 1.2077618e-03, 5.2105282e-02,\n",
       "        1.9812737e-02, 2.7237987e-04, 2.5520786e-03, 1.1560542e-02,\n",
       "        3.0454653e-03, 1.7658397e-04, 1.2216343e-04, 4.0045302e-04,\n",
       "        3.2380641e-02, 6.8046630e-04, 8.6587074e-04, 7.3830173e-03,\n",
       "        2.0544622e-03, 1.2709297e-02, 2.9041249e-01, 2.9081434e-03,\n",
       "        1.3100549e-04, 6.2592456e-04, 1.9799732e-02, 9.2905393e-05,\n",
       "        2.5887995e-03, 4.1228117e-04, 9.9389371e-04, 1.0646492e-03,\n",
       "        2.6749523e-04, 2.5203370e-04, 8.8576204e-04, 5.1020255e-04,\n",
       "        2.4679501e-04, 4.5007057e-04, 8.4726932e-04, 9.4777271e-03,\n",
       "        2.2201045e-01, 2.1934017e-04, 5.1938919e-03, 6.9408992e-04,\n",
       "        1.4908448e-03, 1.1209560e-03, 1.1442811e-03, 2.8410770e-03,\n",
       "        1.4088508e-04, 6.1194127e-04, 5.9482665e-03, 5.5726403e-03,\n",
       "        2.8317893e-04, 4.3046084e-04, 4.5074153e-04, 3.1565309e-03,\n",
       "        1.5770158e-03, 4.0650525e-04, 1.7262815e-02, 4.2454564e-04,\n",
       "        9.7390998e-04, 1.2946084e-04, 1.0597570e-04, 1.2157423e-03,\n",
       "        2.7686150e-03, 4.3327240e-03, 8.1711815e-04, 6.1223377e-04,\n",
       "        2.6317323e-03, 8.4884008e-03, 1.4561147e-02, 1.3022286e-04,\n",
       "        4.0385447e-04, 1.2807062e-04, 3.8981077e-03, 5.0943339e-04,\n",
       "        9.2855131e-04, 6.8927323e-04, 9.7916718e-04, 2.2061527e-04,\n",
       "        1.5688942e-01, 3.0725592e-04, 2.5755432e-02, 2.0627587e-03,\n",
       "        7.6528924e-04],\n",
       "       [2.2070105e-03, 2.2088908e-04, 1.4099558e-03, 6.5941777e-04,\n",
       "        8.1384066e-04, 1.0971891e-04, 9.9605962e-04, 5.9091963e-04,\n",
       "        2.2765866e-03, 4.9165664e-03, 2.8708014e-03, 1.6332643e-02,\n",
       "        4.8615001e-03, 8.8916317e-04, 7.1030756e-04, 2.4105185e-03,\n",
       "        1.2817915e-03, 6.2633632e-04, 3.2429633e-04, 9.0903457e-04,\n",
       "        8.1130676e-02, 3.8975503e-04, 1.2708501e-03, 2.8144713e-03,\n",
       "        7.9336116e-04, 3.0833867e-03, 5.9849107e-01, 5.5164057e-03,\n",
       "        2.2845968e-04, 1.2436884e-03, 1.0596742e-02, 1.9167864e-04,\n",
       "        2.0774233e-03, 6.6580641e-04, 1.2876773e-03, 6.4662710e-04,\n",
       "        3.4325899e-04, 4.3927238e-04, 3.5702987e-04, 1.8382294e-04,\n",
       "        1.0850767e-04, 2.0014434e-04, 7.1075076e-04, 2.1829858e-02,\n",
       "        9.7803816e-02, 1.5141224e-04, 4.9124090e-03, 1.3532045e-03,\n",
       "        1.0306420e-03, 1.0913794e-03, 1.0601594e-03, 1.1779554e-03,\n",
       "        2.8065642e-04, 1.2494565e-03, 5.9735770e-03, 9.2049496e-04,\n",
       "        1.5486708e-04, 5.0411699e-04, 5.1935948e-04, 4.3862541e-03,\n",
       "        2.3813879e-03, 2.5783354e-04, 1.6504370e-02, 7.2705431e-04,\n",
       "        1.4836185e-03, 1.4162020e-04, 1.1792266e-04, 2.2911949e-03,\n",
       "        6.3983523e-03, 7.5113284e-03, 6.4330135e-04, 4.7036482e-04,\n",
       "        1.3413269e-03, 8.2413629e-03, 5.4798983e-03, 1.3244904e-04,\n",
       "        3.4611620e-04, 4.0038681e-04, 2.1130436e-03, 2.1084178e-04,\n",
       "        4.6539062e-04, 6.9968955e-04, 8.6618174e-04, 3.3011209e-04,\n",
       "        3.4008447e-02, 2.1762987e-04, 2.3894627e-03, 9.3630858e-04,\n",
       "        3.0499182e-04],\n",
       "       [2.6141794e-03, 5.8552827e-04, 1.8352451e-03, 1.4850877e-03,\n",
       "        1.2799094e-03, 1.1126219e-04, 1.2665527e-03, 4.1438840e-04,\n",
       "        1.6864669e-03, 3.4582859e-03, 2.8043615e-03, 3.3322554e-02,\n",
       "        3.1681112e-03, 1.9081837e-03, 1.3772408e-03, 2.3497890e-03,\n",
       "        3.7832751e-03, 1.2290211e-03, 7.4769527e-04, 7.4992189e-04,\n",
       "        7.7708423e-02, 3.5512933e-04, 1.4781160e-03, 5.7190345e-03,\n",
       "        1.4040375e-03, 4.1903742e-03, 5.8107698e-01, 3.1823374e-03,\n",
       "        2.6399881e-04, 1.5605467e-03, 6.6357339e-03, 2.5844044e-04,\n",
       "        2.8576253e-03, 5.8052799e-04, 1.2768310e-03, 1.0455137e-03,\n",
       "        6.0238212e-04, 3.7984955e-04, 5.6746911e-04, 2.1244341e-04,\n",
       "        1.6552331e-04, 1.9079288e-04, 9.2335703e-04, 4.5340780e-02,\n",
       "        3.1357110e-02, 1.5375004e-04, 3.0652187e-03, 1.3281032e-03,\n",
       "        9.2384062e-04, 1.4217601e-03, 1.1409268e-03, 1.6225540e-03,\n",
       "        3.0139062e-04, 1.4708082e-03, 8.5026538e-03, 2.0273339e-03,\n",
       "        2.1382782e-04, 4.9771537e-04, 6.0724159e-04, 3.6698813e-03,\n",
       "        2.5161209e-03, 3.0016922e-04, 2.2257108e-02, 7.6107355e-04,\n",
       "        2.6992799e-03, 2.7909345e-04, 1.6981871e-04, 3.8789089e-03,\n",
       "        3.6557759e-03, 9.3910256e-03, 9.2837057e-04, 8.8052411e-04,\n",
       "        1.3543041e-03, 8.0323322e-03, 3.1881134e-03, 1.3630152e-04,\n",
       "        3.5693805e-04, 7.2042434e-04, 3.7732671e-03, 2.3685000e-04,\n",
       "        4.3003078e-04, 1.0125447e-03, 2.1727397e-03, 2.0130184e-04,\n",
       "        5.9862535e-02, 5.9945480e-04, 4.8713260e-03, 2.3112707e-03,\n",
       "        5.6537049e-04],\n",
       "       [3.2859778e-03, 4.1442396e-04, 2.7887330e-03, 1.1977057e-03,\n",
       "        1.1988176e-03, 2.2339703e-04, 2.3771636e-03, 9.5489429e-04,\n",
       "        4.3733902e-03, 7.5512445e-03, 5.6658634e-03, 3.5138141e-02,\n",
       "        5.8382628e-03, 2.1230844e-03, 1.1508726e-03, 2.9609061e-03,\n",
       "        1.8849692e-03, 1.1952263e-03, 5.9132115e-04, 2.1279310e-03,\n",
       "        1.0585287e-01, 5.7044689e-04, 2.5581508e-03, 5.4293349e-03,\n",
       "        1.5660959e-03, 4.4075781e-03, 3.8256034e-01, 7.6264832e-03,\n",
       "        2.8982764e-04, 2.2312992e-03, 1.1590865e-02, 2.6539477e-04,\n",
       "        3.3694569e-03, 1.0620814e-03, 2.0352765e-03, 1.2418032e-03,\n",
       "        5.6141871e-04, 7.8185368e-04, 7.3540240e-04, 3.2215958e-04,\n",
       "        2.1984152e-04, 3.6598922e-04, 1.0512726e-03, 5.2958991e-02,\n",
       "        1.6651982e-01, 2.8935901e-04, 5.6012855e-03, 1.8419767e-03,\n",
       "        2.2835617e-03, 1.6481716e-03, 1.6091198e-03, 1.3886424e-03,\n",
       "        4.6710260e-04, 2.0060437e-03, 1.0831285e-02, 1.3861562e-03,\n",
       "        2.5769105e-04, 7.0694904e-04, 7.3087390e-04, 6.3377307e-03,\n",
       "        4.2890101e-03, 4.1433150e-04, 2.1096369e-02, 9.7397587e-04,\n",
       "        2.1989364e-03, 2.0177659e-04, 2.0953891e-04, 4.6422961e-03,\n",
       "        6.4189052e-03, 1.2974111e-02, 1.0272872e-03, 6.4036774e-04,\n",
       "        1.8785337e-03, 1.2710362e-02, 4.9520726e-03, 2.0928666e-04,\n",
       "        6.1129843e-04, 8.7232067e-04, 4.0258951e-03, 3.4938223e-04,\n",
       "        8.1443950e-04, 9.8222075e-04, 1.5091291e-03, 6.6438765e-04,\n",
       "        3.3166341e-02, 3.4473732e-04, 3.0515643e-03, 1.5940127e-03,\n",
       "        5.7476253e-04]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xception.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-250647972685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_class' is not defined"
     ]
    }
   ],
   "source": [
    "df_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train_Final-Copy1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
